{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import css_from_file\n",
    "css_from_file('style/style.css')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from the file __data/boehringer/(train|test).csv__ from the data folder. \n",
    "\n",
    "The first column is a binary variable that you want to predict. The rest are numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(path):\n",
    "    df = pd.read_csv(path)\n",
    "    if \"Activity\" not in df.columns:\n",
    "        df[\"Activity\"] = np.nan\n",
    "    return df.drop(\"Activity\",axis=1), df.Activity\n",
    "    \n",
    "X_tr, y_tr = load(\"data/boehringer/train.csv\")\n",
    "X_te, y_te = load(\"data/boehringer/test.csv\")\n",
    "\n",
    "print(\"training data shape\", X_tr.shape)\n",
    "print(\"testing data shape\", X_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise\n",
    "---------------------\n",
    "\n",
    "Using the starter code below try to improve the solution\n",
    "\n",
    "1. What kind of models you can use?\n",
    "2. Try changing model parameters to get the best cross validation error.\n",
    "3. Use pipeline to transform features before modeling:\n",
    "   - use some feature selection mechanism\n",
    "   - use dimension reduction method (pca, svd, etc)\n",
    "   \n",
    "Tip: It is ok to loop over models and datasets like this.\n",
    "\n",
    "```python\n",
    "for data in [pipeline_1, pipeline_2, pipeline_3]:\n",
    "    for model in [model_1, model_2, model_3]:\n",
    "        # do stuff\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from cross_validation import cross_val_apply\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import LogisticRegression, BayesianRidge, SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(n_jobs=-1, n_estimators=100), \n",
    "                   param_grid={'max_depth':[5,10,15]})\n",
    "\n",
    "%time oof_predictions = cross_val_apply(clf, X_tr, y_tr, decision_func=\"predict_proba\")\n",
    "\n",
    "err = log_loss(y_tr, oof_predictions)\n",
    "print(\"Your error is\", err)\n",
    "if err > 0.5:\n",
    "    print(\"You can still improve :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Examples of classifiers \n",
    "\n",
    "<div class='spoiler'>\n",
    "\n",
    "clf1 = RandomForestClassifier(n_estimators=10,n_jobs=-1)\n",
    "clf2 = make_pipeline(PCA(), LogisticRegression())\n",
    "\n",
    "clf3 = make_pipeline(\n",
    "   make_union(\n",
    "       RandomTreesEmbedding(n_estimators=10), \n",
    "       LazyTransformer()\n",
    "   ), \n",
    "   LogisticRegression()\n",
    ")\n",
    "\n",
    "for clf in [clf1,clf2,clf3]:\n",
    "    clf.fit(x,y)\n",
    "    \n",
    "clf = make_pipeline(make_union(make_pipeline(RandomTreesEmbedding(n_estimators=20), StandardScaler(with_mean=False)), \n",
    "                               make_pipeline(StandardScaler(with_mean=False), VarianceThreshold(0.1))),\n",
    "                    MLPClassifier((15,), alpha=15.0, verbose=True))\n",
    "\n",
    "clf = BaggingClassifier(make_pipeline(\n",
    "                        make_union(RandomTreesEmbedding(n_estimators=10), \n",
    "                                   LazyTransformer()),\n",
    "                        StandardScaler(with_mean=False), \n",
    "                        VarianceThreshold(0.001),\n",
    "                        MLPClassifier((25,), alpha=10.0, verbose=False)), \n",
    "                        max_samples=0.75,\n",
    "                        max_features=0.75,\n",
    "                        n_estimators=10)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_tr, y_tr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
