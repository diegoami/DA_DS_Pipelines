{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/*@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "}\n",
       "@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tfont-weight: bold;\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "}\n",
       "@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tfont-style: oblique;\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "}\n",
       "@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tfont-weight: bold;\n",
       "\tfont-style: oblique;\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "}*/\n",
       "\n",
       ".navbar-brand, .current_kernel_logo {display:none}\n",
       ".container {\n",
       "    width:80%;    \n",
       "}\n",
       "\n",
       "h1 {\n",
       "\tfont-family: Helvetica, serif;\n",
       "}\n",
       "h4{\n",
       "\tmargin-top:12px;\n",
       "\tmargin-bottom: 3px;\n",
       "   }\n",
       "div.text_cell_render{\n",
       "\tfont-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "\tline-height: 145%;\n",
       "\tfont-size: 100%;\n",
       "\twidth:100%;\n",
       "\tmargin-left:auto;\n",
       "\tmargin-right:auto;\n",
       "}\n",
       ".CodeMirror{\n",
       "\t\tfont-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "}\n",
       ".text_cell_render h5 {\n",
       "\tfont-weight: 300;\n",
       "\tfont-size: 22pt;\n",
       "\t/*color: #4057A1;*/\n",
       "\tfont-style: italic;\n",
       "\tmargin-bottom: .5em;\n",
       "\tmargin-top: 0.5em;\n",
       "\tdisplay: block;\n",
       "}\n",
       "\n",
       ".warning{\n",
       "\tcolor: rgb( 240, 20, 20 )\n",
       "\t}   \n",
       "\n",
       "div.spoiler {\n",
       "\tdisplay: none;\n",
       "}\n",
       "\n",
       ".rendered_html code {\n",
       "\tborder: 0;\n",
       "\t/*background-color: #eee;*/\n",
       "\tfont-size: 100%;\n",
       "\tpadding: 1px 2px;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import css_from_file\n",
    "css_from_file('style/style.css')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda3/envs/pipeline/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from the file __data/boehringer/(train|test).csv__ from the data folder. \n",
    "\n",
    "The first column is a binary variable that you want to predict. The rest are numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape (3751, 1776)\n",
      "testing data shape (2501, 1776)\n"
     ]
    }
   ],
   "source": [
    "def load(path):\n",
    "    df = pd.read_csv(path)\n",
    "    if \"Activity\" not in df.columns:\n",
    "        df[\"Activity\"] = np.nan\n",
    "    return df.drop(\"Activity\",axis=1), df.Activity\n",
    "    \n",
    "X_tr, y_tr = load(\"data/boehringer/train.csv\")\n",
    "X_te, y_te = load(\"data/boehringer/test.csv\")\n",
    "\n",
    "print(\"training data shape\", X_tr.shape)\n",
    "print(\"testing data shape\", X_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = X_tr[:1000]\n",
    "y_tr = y_tr[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise\n",
    "---------------------\n",
    "\n",
    "Using the starter code below try to improve the solution\n",
    "\n",
    "1. What kind of models you can use?\n",
    "2. Try changing model parameters to get the best cross validation error.\n",
    "3. Use pipeline to transform features before modeling:\n",
    "   - use some feature selection mechanism\n",
    "   - use dimension reduction method (pca, svd, etc)\n",
    "   \n",
    "Tip: It is ok to loop over models and datasets like this.\n",
    "\n",
    "```python\n",
    "for data in [pipeline_1, pipeline_2, pipeline_3]:\n",
    "    for model in [model_1, model_2, model_3]:\n",
    "        # do stuff\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 45s, sys: 11 s, total: 5min 56s\n",
      "Wall time: 2min 38s\n",
      "{'scoring': None, 'estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False), 'n_jobs': 1, 'fit_params': {}, 'iid': True, 'refit': True, 'cv': None, 'verbose': 0, 'pre_dispatch': '2*n_jobs', 'error_score': 'raise', 'param_grid': {'min_samples_leaf': [40, 50, 60], 'max_depth': [50, 60, 70]}, 'scorer_': <function _passthrough_scorer at 0x7f0357791598>, 'grid_scores_': [mean: 0.74140, std: 0.00389, params: {'max_depth': 50, 'min_samples_leaf': 40}, mean: 0.73794, std: 0.00207, params: {'max_depth': 50, 'min_samples_leaf': 50}, mean: 0.73447, std: 0.00436, params: {'max_depth': 50, 'min_samples_leaf': 60}, mean: 0.74140, std: 0.00389, params: {'max_depth': 60, 'min_samples_leaf': 40}, mean: 0.73794, std: 0.00207, params: {'max_depth': 60, 'min_samples_leaf': 50}, mean: 0.73447, std: 0.00436, params: {'max_depth': 60, 'min_samples_leaf': 60}, mean: 0.74140, std: 0.00389, params: {'max_depth': 70, 'min_samples_leaf': 40}, mean: 0.73794, std: 0.00207, params: {'max_depth': 70, 'min_samples_leaf': 50}, mean: 0.73447, std: 0.00436, params: {'max_depth': 70, 'min_samples_leaf': 60}], 'best_params_': {'max_depth': 50, 'min_samples_leaf': 40}, 'best_score_': 0.7414022927219408, 'best_estimator_': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=40,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)}\n",
      "Your error is 0.549591959862\n",
      "You can still improve :)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from cross_validation  import cross_val_apply\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import LogisticRegression, BayesianRidge, SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "\n",
    "min_samples_leaf : 40\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(n_jobs=-1, n_estimators=100, random_state=42), \n",
    "                   param_grid={'min_samples_leaf' : [ 40, 50, 60], 'max_depth' : [50, 60, 70]})\n",
    "\n",
    "%time oof_predictions = cross_val_apply(clf, X_tr, y_tr, decision_func='predict_proba')\n",
    "err = log_loss(y_tr, oof_predictions)\n",
    "clf.fit(X_tr, y_tr)\n",
    "print(clf.__dict__)\n",
    "print(\"Your error is\", err)\n",
    "if err > 0.5:\n",
    "    print(\"You can still improve :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from cross_validation  import cross_val_apply\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import LogisticRegression, BayesianRidge, SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from xgboost import XGBClassifier \n",
    "#max_depth : 10\n",
    "#min_child_weight: 8\n",
    "#gamma : 0.4\n",
    "#colsample_bytree: 0.8\n",
    "#subsample': 0.8\n",
    "#reg_alpha = 0.01\n",
    "\n",
    "clf = GridSearchCV(XGBClassifier(), \n",
    "                   param_grid={ 'max_depth':[10 ],\n",
    " 'min_child_weight':[  8]\n",
    "                               , 'gamma':[  0.4], \n",
    "                               'subsample':[0.8],\n",
    " 'colsample_bytree':[ 0.8],\n",
    "                               'reg_alpha':[0.01],\n",
    "                               'n_estimators' :  [500, 1000, 2000]\n",
    "                              }, verbose=True)\n",
    "\n",
    "#%time oof_predictions = cross_val_apply(clf, X_tr, y_tr, decision_func='predict_proba')\n",
    "#err = log_loss(y_tr, oof_predictions)\n",
    "clf.fit(X_tr, y_tr)\n",
    "print(clf.__dict__)\n",
    "#print(\"Your error is\", err)\n",
    "#if err > 0.5:\n",
    "#    print(\"You can still improve :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from cross_validation  import cross_val_apply\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import LogisticRegression, BayesianRidge, SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from xgboost import XGBClassifier \n",
    "#max_depth : 8\n",
    "#min_child_weight: 7\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler(copy=True, with_mean=False, with_std=False)),\n",
    "    ('sgd', SGDClassifier())\n",
    "])\n",
    "clf = GridSearchCV(pipeline,  \n",
    "                   param_grid={ 'sgd_alpha':[0.001, 0.0001, 0.00001] }, verbose=True)\n",
    "\n",
    "#%time oof_predictions = cross_val_apply(clf, X_tr, y_tr, decision_func='predict_proba')\n",
    "#err = log_loss(y_tr, oof_predictions)\n",
    "clf.fit(X_tr, y_tr)\n",
    "print(clf.__dict__)\n",
    "print(\"Your error is\", err)\n",
    "if err > 0.5:\n",
    "    print(\"You can still improve :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Examples of classifiers \n",
    "\n",
    "<div class='spoiler'>\n",
    "\n",
    "clf1 = RandomForestClassifier(n_estimators=10,n_jobs=-1)\n",
    "clf2 = make_pipeline(PCA(), LogisticRegression())\n",
    "\n",
    "clf3 = make_pipeline(\n",
    "   make_union(\n",
    "       RandomTreesEmbedding(n_estimators=10), \n",
    "       LazyTransformer()\n",
    "   ), \n",
    "   LogisticRegression()\n",
    ")\n",
    "\n",
    "for clf in [clf1,clf2,clf3]:\n",
    "    clf.fit(x,y)\n",
    "    \n",
    "clf = make_pipeline(make_union(make_pipeline(RandomTreesEmbedding(n_estimators=20), StandardScaler(with_mean=False)), \n",
    "                               make_pipeline(StandardScaler(with_mean=False), VarianceThreshold(0.1))),\n",
    "                    MLPClassifier((15,), alpha=15.0, verbose=True))\n",
    "\n",
    "clf = BaggingClassifier(make_pipeline(\n",
    "                        make_union(RandomTreesEmbedding(n_estimators=10), \n",
    "                                   LazyTransformer()),\n",
    "                        StandardScaler(with_mean=False), \n",
    "                        VarianceThreshold(0.001),\n",
    "                        MLPClassifier((25,), alpha=10.0, verbose=False)), \n",
    "                        max_samples=0.75,\n",
    "                        max_features=0.75,\n",
    "                        n_estimators=10)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(X_tr, y_tr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
