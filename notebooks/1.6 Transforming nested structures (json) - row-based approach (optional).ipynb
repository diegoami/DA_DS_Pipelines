{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes your input data can be nested with more difficult structure than a simple table or a matrix.\n",
    "\n",
    "In such cases it is sometime useful to shift mental orientation to analyze and extract information froms rows rather then non-defined columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import css_from_file\n",
    "css_from_file('style/style.css')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pprint\n",
    "from nltk import download, word_tokenize\n",
    "\n",
    "download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/companies/companies.json\") as dataf:\n",
    "    data = [json.loads(line) for line in dataf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of deeply nested data with various data types:\n",
    "\n",
    "Exercise:\n",
    "\n",
    "1. Name variable types\n",
    "2. What do you do with lists, geo location?\n",
    "3. What do you do with counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(data[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With such data you can be sure that you'll need a sparse matrix.\n",
    "\n",
    "Remember `DictVectorizer` class? It accepts a dictionary and returns a sparse matrix.\n",
    "\n",
    "So the only thing we need is a function such that \n",
    "\n",
    "```f(Json) => Dict```\n",
    "\n",
    "First we need a function `deep_select` to retrieve nested values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### write your deep_select class here\n",
    "\n",
    "jsondata = {'a': \n",
    "    {'b': \n",
    "         {'c': 1}\n",
    "    }\n",
    "}\n",
    "\n",
    "class DeepSelect():\n",
    "    def __init__(self, path, default):\n",
    "        self.path = path\n",
    "        self.default = default\n",
    "    \n",
    "    def _helper(self, row, path):\n",
    "        if len(path) == 1:\n",
    "            return row.get(path[0], self.default)\n",
    "        elif path[0] in row:\n",
    "            return self._helper(row[path[0]], path[1:])\n",
    "        else:\n",
    "            return self.default\n",
    "\n",
    "    def __call__(self, row):\n",
    "        return self._helper(row, self.path)\n",
    "\n",
    "# tests\n",
    "assert DeepSelect([\"a\",\"b\",\"c\"], None)(jsondata) == 1\n",
    "assert DeepSelect([\"a\",\"b\"], None)(jsondata) == {'c': 1}\n",
    "assert DeepSelect([\"x\"], None)(jsondata) == None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click here to see the DeepSelect solution\n",
    "<div class=\"spoiler\">\n",
    "\n",
    "class DeepSelect():\n",
    "    def __init__(self, path, default):\n",
    "        self.path = path\n",
    "        self.default = default\n",
    "    \n",
    "    def _helper(self, row, path):\n",
    "        if len(path) == 1:\n",
    "            return row.get(path[0], self.default)\n",
    "        elif path[0] in row:\n",
    "            return self._helper(row[path[0]], path[1:])\n",
    "        else:\n",
    "            return self.default\n",
    "\n",
    "    def __call__(self, row):\n",
    "        return self._helper(row, self.path)\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_skills_features(row):\n",
    "    features = {}\n",
    "    for tech in DeepSelect(['extension','skills'],[])(row):\n",
    "        features[tech['skill']] = tech[\"count\"]\n",
    "    return features\n",
    "\n",
    "create_skills_features(data[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good what about text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_description_features(row):\n",
    "    features = {}\n",
    "    for word in word_tokenize(row['description']):\n",
    "        features[\"description=\" + word.lower()] = 1\n",
    "    return features\n",
    "\n",
    "create_description_features(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a more generic way to transform text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformText():\n",
    "    def __init__(self, field, tokenizer=word_tokenize):\n",
    "        self.field = field\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __call__(self, row):\n",
    "        features = {}\n",
    "        for word in self.tokenizer(DeepSelect(self.field,\"\")(row)):\n",
    "            word = word.lower()\n",
    "            features[word] = 1\n",
    "        return features\n",
    "    \n",
    "text_transformer = TransformText(['extension','address'], tokenizer=lambda x: [x])\n",
    "text_transformer(data[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise:\n",
    "-------------\n",
    "    \n",
    "1. Write function or classes that transform other features? You'll need a function to retrieve nested values. \n",
    "2. There are some fields which you can treat as a categorical feature or a text features. What is best and why?\n",
    "3. Write a function / class that will accept a list of transforming functions and creates a concatenation of the features\n",
    "4. Wrap previous function in a scikit-learn transformer class so we can use it in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(fs):\n",
    "\n",
    "    def helper(row):\n",
    "        all_features = {}\n",
    "        for name, f in fs:\n",
    "            for k,v in f(row).items():\n",
    "                all_features[name + \"_\" + k] = v\n",
    "        return all_features\n",
    "\n",
    "    return helper\n",
    "\n",
    "company_data = {\n",
    "    'description': 'Fortune 500 hundred company',\n",
    "    'skills': [{'skill': 'waste disposal', 'count': 1},\n",
    "               {'skill': 'data science', 'count': 2}]\n",
    "}\n",
    "\n",
    "\n",
    "features_generator = combine_features([('description', TransformText(['description'])),\n",
    "                                       ('skills', create_skills_features)]) \n",
    "\n",
    "features_generator(company_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "class JsonTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, fs):\n",
    "        self.fs = fs\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        out = []\n",
    "        for x in X:\n",
    "            out.append(combine_features(self.fs)(x))\n",
    "        return out\n",
    "    \n",
    "pipeline = make_pipeline(\n",
    "    JsonTransformer([('description', TransformText(['description'])), \n",
    "                     ('skills', create_skills_features)]),\n",
    "    DictVectorizer()\n",
    ")\n",
    "\n",
    "pipeline.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pipeline.fit_transform(data)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of features is really high. We need to reduce this. We can remove too sparse values.\n",
    "To check the sparsity of the data we can use a method\n",
    "\n",
    "X.getnnz (number of non-zero values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.getnnz(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise\n",
    "===============\n",
    "\n",
    "1. Write a transformation class called SparsityFilter that accepts a minimum frequency. Watch out for fit function - this class has some state that you must save\n",
    "\n",
    "```\n",
    "class SparsityFilter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, min_nnz=None):\n",
    "        self.min_nnz = min_nnz\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        ???\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return ???\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write sparsity class here\n",
    "class SparsityFilter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, min_nnz=None):\n",
    "        self.min_nnz = min_nnz\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.sparsity = X.getnnz(0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.sparsity >= self.min_nnz]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double click to see the solution \n",
    "\n",
    "<div class=\"spoiler\">\n",
    "\n",
    "class SparsityFilter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, min_nnz=None):\n",
    "        self.min_nnz = min_nnz\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.sparsity = X.getnnz(0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.sparsity >= self.min_nnz]\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    JsonTransformer([('description', TransformText(['description'])), \n",
    "                     ('skills', create_skills_features)]),\n",
    "    DictVectorizer(),\n",
    "    SparsityFilter(min_nnz=25)\n",
    ")\n",
    "\n",
    "X = pipeline.fit_transform(data)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a shape that is much smaller than the original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise\n",
    "================\n",
    "\n",
    "1. Build a model - try to predict the industry.\n",
    "2. Evaluate its results using cross validation - what would be the best measure for this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click to see the solution\n",
    "\n",
    "<div class=\"spoiler\">\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    JsonTransformer([('description', TransformText('description')), \n",
    "                     ('technologies', create_technologies_features)]),\n",
    "    DictVectorizer(),\n",
    "    SparsityFilter(min_nnz=25),\n",
    "    XGBClassifier()\n",
    ")\n",
    "\n",
    "X = data\n",
    "y = [row['industries'][0] if len(row['industries']) else \"\" for row in data]\n",
    "\n",
    "predictions = cross_val_predict(pipeline, X, y)\n",
    "\n",
    "print(\"Accuracy = {}\".format((predictions == np.array(y)).mean()))\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def makelist(x):\n",
    "    return [x]\n",
    "    \n",
    "pipeline = make_pipeline(\n",
    "    JsonTransformer([('description', TransformText(['description'])),\n",
    "                     ('country', TransformText(['extension','geo_location','country'], makelist)),\n",
    "                     ('skills', create_skills_features)]),\n",
    "    DictVectorizer(),\n",
    "    SparsityFilter(min_nnz=25),\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "X = data\n",
    "y = [row['industries'][0] if len(row['industries']) else \"\" for row in data]\n",
    "\n",
    "predictions = cross_val_predict(pipeline, X, y)\n",
    "\n",
    "print(\"Accuracy = {}\".format((predictions == np.array(y)).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
