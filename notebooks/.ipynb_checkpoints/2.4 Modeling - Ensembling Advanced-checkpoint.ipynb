{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import css_from_file\n",
    "css_from_file('style/style.css')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "def load(path):\n",
    "    df = pd.read_csv(path)\n",
    "    if \"Activity\" not in df.columns:\n",
    "        df[\"Activity\"] = np.nan\n",
    "    return df.drop(\"Activity\",axis=1), df.Activity\n",
    "    \n",
    "X_tr, y_tr = load(\"data/boehringer/train.csv\")\n",
    "X_te, y_te = load(\"data/boehringer/test.csv\")\n",
    "\n",
    "print(\"training data shape\", X_tr.shape)\n",
    "print(\"testing data shape\", X_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking\n",
    "---------------------------\n",
    "\n",
    "In general stacking is a method of blending the models where you treat the predictions from 1 set of models as features for another model. You can think about comittee of experts. In time you are learning who to listen to.\n",
    "\n",
    "In previous exercise we used a very simple way to combine models together.\n",
    "We used a linear combination of predictions\n",
    "\n",
    "There is an excellent article about ensembling here: http://mlwave.com/kaggle-ensembling-guide/\n",
    "\n",
    "Another great source of information: https://www.kaggle.com/c/otto-group-product-classification-challenge/forums/t/14335/1st-place-winner-solution-gilberto-titericz-stanislav-semenov - here you can see stacking in action\n",
    "\n",
    "Exercise\n",
    "----------------------\n",
    "\n",
    "1. Read code below and understand what it does?\n",
    "2. Try to use your classifier from the previous exercise? Does stacking improve a simple average?\n",
    "3. Try other `mixer` models.\n",
    "4. After fitting LogisticRegression mixer look at the `coef_` parameter. Which model has the highest weight?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stacked_classifier import StackedClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from cross_validation import cross_val_apply\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import BaggingClassifier, RandomTreesEmbedding, ExtraTreesClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clfs = [\n",
    "]\n",
    "\n",
    "\n",
    "stacked_classifier = StackedClassifier(estimators=clfs,\n",
    "                                       mixer=SGDClassifier(loss='log'),\n",
    "                                       cv=3,\n",
    "                                       n_jobs=-1,\n",
    "                                       probability=True)\n",
    "\n",
    "oof_predictions = cross_val_apply(stacked_classifier,\n",
    "                                  X_tr,\n",
    "                                  y_tr,\n",
    "                                  cv=4,\n",
    "                                  n_jobs=-1, \n",
    "                                  decision_func=\"predict_proba\")\n",
    "\n",
    "err = log_loss(y_tr, oof_predictions)\n",
    "print(\"Your error is\", err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Double click to see the answers\n",
    "\n",
    "<div class=\"spoiler\">\n",
    "from stacked_classifier import StackedClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from cross_validation import cross_val_apply\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import BaggingClassifier, RandomTreesEmbedding, ExtraTreesClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "class LazyTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        return x\n",
    "\n",
    "nn_forest = BaggingClassifier(make_pipeline(\n",
    "                        make_union(RandomTreesEmbedding(n_estimators=10), \n",
    "                                   LazyTransformer()),\n",
    "                        StandardScaler(with_mean=False), \n",
    "                        VarianceThreshold(0.001),\n",
    "                        MLPClassifier((25,), alpha=10.0, verbose=False)), \n",
    "                        max_samples=0.75,\n",
    "                        max_features=0.75,\n",
    "                        n_estimators=10)\n",
    "\n",
    "clfs = [\n",
    "    ('nn_forest', nn_forest),\n",
    "    ('rf',RandomForestClassifier(n_estimators=100,n_jobs=1)),\n",
    "    ('rf_entropy',RandomForestClassifier(n_estimators=200, n_jobs=-1, criterion='entropy', max_depth=20, \n",
    "                                 min_samples_split=2, min_samples_leaf=1, max_features=250, \n",
    "                                 max_leaf_nodes=300, bootstrap=True, \n",
    "                                 oob_score=False, random_state=123, \n",
    "                                 verbose=0, warm_start=False, class_weight=None)),\n",
    "    ('rf_entropy_3', RandomForestClassifier(n_estimators=300,n_jobs=-1, criterion = 'entropy', max_depth = 50,\n",
    "                                 max_features = 350, random_state = 123)),\n",
    "    ('rf_3', RandomForestClassifier(min_samples_leaf = 2, min_samples_split = 4, n_estimators = 200)),\n",
    "    ('xgb_1', XGBClassifier(n_estimators=200, max_depth=6)),\n",
    "    ('xgb_2', XGBClassifier(n_estimators=200, max_depth=6, min_child_weight=5)),\n",
    "    ('bag', BaggingClassifier(n_estimators=100)),\n",
    "    ('svc', make_pipeline(StandardScaler(), SVC(probability=True))\n",
    "]\n",
    "\n",
    "clfs = [est for _, est in clfs]\n",
    "\n",
    "stacked_classifier = StackedClassifier(estimators=clfs,\n",
    "                                       mixer=ExtraTreesClassifier(),\n",
    "                                       cv=3,\n",
    "                                       n_jobs=-1,\n",
    "                                       probability=True)\n",
    "\n",
    "oof_predictions = cross_val_apply(stacked_classifier,\n",
    "                                  X_tr,\n",
    "                                  y_tr,\n",
    "                                  cv=4,\n",
    "                                  n_jobs=-1, \n",
    "                                  decision_func=\"predict_proba\")\n",
    "\n",
    "err = log_loss(y_tr, oof_predictions)\n",
    "print(\"Your error is\", err)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
