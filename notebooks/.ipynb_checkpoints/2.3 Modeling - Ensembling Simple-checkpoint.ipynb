{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/*@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "}\n",
       "@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tfont-weight: bold;\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "}\n",
       "@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tfont-style: oblique;\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "}\n",
       "@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tfont-weight: bold;\n",
       "\tfont-style: oblique;\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "}*/\n",
       "\n",
       ".navbar-brand, .current_kernel_logo {display:none}\n",
       ".container {\n",
       "    width:80%;    \n",
       "}\n",
       "\n",
       "h1 {\n",
       "\tfont-family: Helvetica, serif;\n",
       "}\n",
       "h4{\n",
       "\tmargin-top:12px;\n",
       "\tmargin-bottom: 3px;\n",
       "   }\n",
       "div.text_cell_render{\n",
       "\tfont-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "\tline-height: 145%;\n",
       "\tfont-size: 100%;\n",
       "\twidth:100%;\n",
       "\tmargin-left:auto;\n",
       "\tmargin-right:auto;\n",
       "}\n",
       ".CodeMirror{\n",
       "\t\tfont-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "}\n",
       ".text_cell_render h5 {\n",
       "\tfont-weight: 300;\n",
       "\tfont-size: 22pt;\n",
       "\t/*color: #4057A1;*/\n",
       "\tfont-style: italic;\n",
       "\tmargin-bottom: .5em;\n",
       "\tmargin-top: 0.5em;\n",
       "\tdisplay: block;\n",
       "}\n",
       "\n",
       ".warning{\n",
       "\tcolor: rgb( 240, 20, 20 )\n",
       "\t}   \n",
       "\n",
       "div.spoiler {\n",
       "\tdisplay: none;\n",
       "}\n",
       "\n",
       ".rendered_html code {\n",
       "\tborder: 0;\n",
       "\t/*background-color: #eee;*/\n",
       "\tfont-size: 100%;\n",
       "\tpadding: 1px 2px;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import css_from_file\n",
    "css_from_file('style/style.css')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape (3751, 1776)\n",
      "testing data shape (2501, 1776)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "def load(path):\n",
    "    df = pd.read_csv(path)\n",
    "    if \"Activity\" not in df.columns:\n",
    "        df[\"Activity\"] = np.nan\n",
    "    return df.drop(\"Activity\",axis=1), df.Activity\n",
    "    \n",
    "X_tr, y_tr = load(\"data/boehringer/train.csv\")\n",
    "X_te, y_te = load(\"data/boehringer/test.csv\")\n",
    "\n",
    "print(\"training data shape\", X_tr.shape)\n",
    "print(\"testing data shape\", X_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise\n",
    "----------------\n",
    "\n",
    "Using your knowledge from 2.1 try to combine many models into a single solution.\n",
    "The simplest way to do this is to use `sklearn.ensemble.VotingClassifier`.\n",
    "\n",
    "1. Read the documentation http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier\n",
    "\n",
    "2. Which method is better for voting (`hard` or `soft`)? Why?\n",
    "\n",
    "3. Use more than 3 different algorithms. Check their performance separately and using VotingClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from cross_validation import cross_val_apply\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import BaggingClassifier, RandomTreesEmbedding\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clfs = [\n",
    "    ('rf', RandomForest()),\n",
    "    ('sgd', make_pipeline(StandardScaler(), SGDClassifier(loss='log')))\n",
    "]\n",
    "\n",
    "voting_clf = ('voting',VotingClassifier(estimators=clfs,voting='soft'))\n",
    "\n",
    "for clf_name, clf in clfs + [voting_clf]:\n",
    "    print(clf_name)\n",
    "    oof_predictions = cross_val_apply(clf, X_tr, y_tr, cv=4,\n",
    "                                      n_jobs=-1, decision_func=\"predict_proba\")\n",
    "\n",
    "    err = log_loss(y_tr, oof_predictions)\n",
    "    print(\"Your error is\", err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Double click to see the answers\n",
    "\n",
    "<div class=\"spoiler\">\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from cross_validation import cross_val_apply\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clfs = [\n",
    "    ('rf',RandomForestClassifier(n_estimators=100,n_jobs=1)),\n",
    "    ('gbm',GradientBoostingClassifier()),\n",
    "    ('et',ExtraTreesClassifier(n_estimators=100,n_jobs=1)),\n",
    "    ('xgb', XGBClassifier()),\n",
    "    ('bag', BaggingClassifier(n_estimators=100)),\n",
    "    ('svm', make_pipeline(StandardScaler(), SVC(probability=True)))\n",
    "]\n",
    "\n",
    "voting_clf = ('voting',VotingClassifier(estimators=clfs,voting='soft'))\n",
    "\n",
    "for clf_name, clf in clfs + [voting_clf]:\n",
    "    print(clf_name)\n",
    "    oof_predictions = cross_val_apply(clf, X_tr, y_tr, cv=4,\n",
    "                                      n_jobs=-1, decision_func=\"predict_proba\")\n",
    "\n",
    "    err = log_loss(y_tr, oof_predictions)\n",
    "    print(\"Your error is\", err)\n",
    "</div>\n",
    "\n",
    "<div class='spoiler'>\n",
    "\n",
    "class LazyTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        return x\n",
    "\n",
    "nn_forest = BaggingClassifier(make_pipeline(\n",
    "                        make_union(RandomTreesEmbedding(n_estimators=10), \n",
    "                                   LazyTransformer()),\n",
    "                        StandardScaler(with_mean=False), \n",
    "                        VarianceThreshold(0.001),\n",
    "                        MLPClassifier((25,), alpha=10.0, verbose=False)), \n",
    "                        max_samples=0.75,\n",
    "                        max_features=0.75,\n",
    "                        n_estimators=10)\n",
    "\n",
    "clfs = [\n",
    "    ('nn_forest', nn_forest),\n",
    "    ('rf',RandomForestClassifier(n_estimators=100,n_jobs=1)),\n",
    "    ('rf_entropy',RandomForestClassifier(n_estimators=200, n_jobs=-1, criterion='entropy', max_depth=20, \n",
    "                                 min_samples_split=2, min_samples_leaf=1, max_features=250, \n",
    "                                 max_leaf_nodes=300, bootstrap=True, \n",
    "                                 oob_score=False, random_state=123, \n",
    "                                 verbose=0, warm_start=False, class_weight=None)),\n",
    "    ('rf_entropy_3', RandomForestClassifier(n_estimators=300,n_jobs=-1, criterion = 'entropy', max_depth = 50,\n",
    "                                 max_features = 350, random_state = 123)),\n",
    "    ('rf_3', RandomForestClassifier(min_samples_leaf = 2, min_samples_split = 4, n_estimators = 200)),\n",
    "    ('xgb_1', XGBClassifier(n_estimators=200, max_depth=6)),\n",
    "    ('xgb_2', XGBClassifier(n_estimators=200, max_depth=6, min_child_weight=5)),\n",
    "    ('bag', BaggingClassifier(n_estimators=100)),\n",
    "    ('et', ExtraTreesClassifier(n_estimators=100,n_jobs=1)),\n",
    "    ('svc', make_pipeline(StandardScaler(), SVC(probability=True)))\n",
    "]\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
